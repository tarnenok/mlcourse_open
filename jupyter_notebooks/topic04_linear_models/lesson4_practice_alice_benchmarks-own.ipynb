{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Автор материала: Юрий Исаков и Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейные модели классификации и регрессии\n",
    "## <center>  Практика. Идентификация пользователя с помощью логистической регрессии\n",
    "\n",
    "Тут мы воспроизведем парочку бенчмарков нашего соревнования и вдохновимся побить третий бенчмарк, а также остальных участников. Веб-формы для отправки ответов тут не будет, ориентир – [leaderboard](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/leaderboard) соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и преобразование данных\n",
    "Зарегистрируйтесь на [Kaggle](www.kaggle.com), если вы не сделали этого раньше, зайдите на [страницу](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования и скачайте данные. Первым делом загрузим обучающую и тестовую выборки и посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('../../data/train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('../../data/test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57     55 2013-01-12 08:05:57      0   \n",
       "54843          56 2013-01-12 08:37:23     55 2013-01-12 08:37:23     56   \n",
       "77292         946 2013-01-12 08:50:13    946 2013-01-12 08:50:14    951   \n",
       "114021        945 2013-01-12 08:50:17    948 2013-01-12 08:50:17    949   \n",
       "146670        947 2013-01-12 08:50:20    950 2013-01-12 08:50:20    948   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT      0                 NaT      0   \n",
       "54843      2013-01-12 09:07:07     55 2013-01-12 09:07:09      0   \n",
       "77292      2013-01-12 08:50:15    946 2013-01-12 08:50:15    946   \n",
       "114021     2013-01-12 08:50:18    948 2013-01-12 08:50:18    945   \n",
       "146670     2013-01-12 08:50:20    947 2013-01-12 08:50:21    950   \n",
       "\n",
       "                         time5  ...                 time6 site7  \\\n",
       "session_id                      ...                               \n",
       "21669                      NaT  ...                   NaT     0   \n",
       "54843                      NaT  ...                   NaT     0   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16   948   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18   947   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21   946   \n",
       "\n",
       "                         time7 site8               time8 site9  \\\n",
       "session_id                                                       \n",
       "21669                      NaT     0                 NaT     0   \n",
       "54843                      NaT     0                 NaT     0   \n",
       "77292      2013-01-12 08:50:16   784 2013-01-12 08:50:16   949   \n",
       "114021     2013-01-12 08:50:19   945 2013-01-12 08:50:19   946   \n",
       "146670     2013-01-12 08:50:21   951 2013-01-12 08:50:22   946   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT      0                 NaT      0  \n",
       "54843                      NaT      0                 NaT      0  \n",
       "77292      2013-01-12 08:50:17    946 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19    946 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22    947 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке содержатся следующие признаки:\n",
    "    - site1 – индекс первого посещенного сайта в сессии\n",
    "    - time1 – время посещения первого сайта в сессии\n",
    "    - ...\n",
    "    - site10 – индекс 10-го посещенного сайта в сессии\n",
    "    - time10 – время посещения 10-го сайта в сессии\n",
    "    - target – целевая переменная, 1 для сессий Элис, 0 для сессий других пользователей\n",
    "    \n",
    "Сессии пользователей выделены таким образом, что они не могут быть длиннее получаса или 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд либо когда сессия заняла по времени более 30 минут.\n",
    "\n",
    "В таблице встречаются пропущенные значения, это значит, что сессия состоит менее, чем из 10 сайтов. Заменим пропущенные значения нулями и приведем признаки к целому типу. Также загрузим словарь сайтов и посмотрим, как он выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34555</th>\n",
       "      <td>i1-js-14-3-01-10005-734090045-i.init.cedexis-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8866</th>\n",
       "      <td>tahiti.oracle.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25771</th>\n",
       "      <td>www.polymtl.ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>www.mindat.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12183</th>\n",
       "      <td>hub.loginradius.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    site\n",
       "34555  i1-js-14-3-01-10005-734090045-i.init.cedexis-r...\n",
       "8866                                   tahiti.oracle.com\n",
       "25771                                     www.polymtl.ca\n",
       "6023                                      www.mindat.org\n",
       "12183                                hub.loginradius.com"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n",
    "                          index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевую переменную и объединим выборки, чтобы вместе привести их к разреженному формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для самой первой модели будем использовать только посещенные сайты в сессии (но не будем обращать внимание на временные признаки). За таким выбором данных для модели стоит такая идея:  *у Элис есть свои излюбленные сайты, и чем чаще вы видим эти сайты в сессии, тем выше вероятность, что это сессия Элис и наоборот.*\n",
    "\n",
    "Подготовим данные, из всей таблицы выберем только признаки `site1, site2, ... , site10`. Напомним, что пропущенные значения заменены нулем. Вот как выглядят первые строки таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сессии представляют собой последовательность индексов сайтов и данные в таком виде неудобны для линейных методов. В соответствии с нашей гипотезой (у Элис есть излюбленные сайты) надо преобразовать эту таблицу таким образом, чтобы каждому возможному сайту соответствовал свой отдельный признак (колонка), а его значение равнялось бы количеству посещений этого сайта в сессии. Это делается в две строчки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (82797, 48371))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse = full_sites_sparse[:idx_split]\n",
    "X_test_sparse = full_sites_sparse[idx_split:]\n",
    "X_train_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=[str(index) for index in sites_dict_df.index])\n",
    "corpus = train_df.drop('target', axis=1)[sites].apply(lambda row: ' '.join([str(index) for index in row.values if index != 0]), axis=1).values\n",
    "X_train_sparse = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=[str(index) for index in sites_dict_df.index])\n",
    "corpus = test_df[sites].apply(lambda row: ' '.join([str(index) for index in row.values if index != 0]), axis=1).values\n",
    "X_test_sparse = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (82797, 48371))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один плюс использования разреженных матриц в том, что для них имеются специальные реализации как матричных операций, так и алгоритмов машинного обучения, что подчас позволяет ощутимо ускорить операции за счет особенностей структуры данных. Это касается и логистической регрессии. Вот теперь у нас все готово для построения нашей первой модели.\n",
    "\n",
    "### 2. Построение первой модели\n",
    "\n",
    "Итак, у нас есть алгоритм и данные для него, построим нашу первую модель, воспользовавшись релизацией [логистической регрессии](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из пакета `sklearn` с параметрами по умолчанию. Первые 90% данных будем использовать для обучения (обучающая выборка отсортирована по времени), а оставшиеся 10% для проверки качества (validation). \n",
    "\n",
    "**Напишите простую функцию, которая будет возвращать качество модели на отложенной выборке, и обучите наш первый классификатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 - ratio), stratify = None, shuffle=False)\n",
    "    est = LogisticRegression(C=C, random_state=seed)\n",
    "    est.fit(X_train, y_train)\n",
    "    return roc_auc_score(y_test, est.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрите, какой получился ROC AUC на отложенной выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92357815290754763"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать эту модель нашей первой отправной точкой (baseline). Для построения модели для прогноза на тестовой выборке **необходимо обучить модель заново уже на всей обучающей выборке** (пока наша модель обучалась лишь на части данных), что повысит ее обобщающую способность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель на всей выборке, сделайте прогноз для тестовой выборки и сделайте посылку в соревновании**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "est = LogisticRegression(random_state=17, n_jobs=-1)\n",
    "est.fit(X_train_sparse, y_train)\n",
    "y_pred = est.predict_proba(X_test_sparse)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(y_pred, './../../data/alice_result1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы выполните эти действия и загрузите ответ на [странице](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования, то воспроизведете первый бенчмарк \"Logit\".\n",
    "\n",
    "### 3. Улучшение модели, построение новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте такой признак, который будет представлять собой число вида ГГГГММ от той даты, когда проходила сессия, например 201407 -- 2014 год и 7 месяц. Таким образом, мы будем учитывать помесячный [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь период предоставленных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train = pd.DataFrame(index=train_df.index)\n",
    "new_test = pd.DataFrame(index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_feature(train, test, feat_name):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train[feat_name].astype('float64').values.reshape(-1, 1))\n",
    "    train[feat_name + '_s'] = scaler.transform(train[feat_name].astype('float64').values.reshape(-1, 1))\n",
    "    test[feat_name + '_s'] = scaler.transform(test[feat_name].astype('float64').values.reshape(-1, 1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте новый признак, предварительно отмасштабировав его с помощью `StandardScaler`, и снова посчитайте ROC AUC на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_sess_start(ts):\n",
    "    return ts.year*100 + ts.month\n",
    "\n",
    "new_train['year_month'] = train_df['time1'].apply(transform_sess_start)\n",
    "new_test['year_month'] = test_df['time1'].apply(transform_sess_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(new_train['year_month'].astype('float64').values.reshape(-1, 1))\n",
    "new_train['year_month_s'] = scaler.transform(new_train['year_month'].astype('float64').values.reshape(-1, 1))\n",
    "new_test['year_month_s'] = scaler.transform(new_test['year_month'].astype('float64').values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201410</td>\n",
       "      <td>0.822948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201407</td>\n",
       "      <td>0.752287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201412</td>\n",
       "      <td>0.870055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201411</td>\n",
       "      <td>0.846501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201405</td>\n",
       "      <td>0.705179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_month  year_month_s\n",
       "session_id                          \n",
       "1               201410      0.822948\n",
       "2               201407      0.752287\n",
       "3               201412      0.870055\n",
       "4               201411      0.846501\n",
       "5               201405      0.705179"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте два новых признака: start_hour и morning.**\n",
    "\n",
    "Признак `start_hour` – это час в который началась сессия (от 0 до 23), а бинарный признак `morning` равен 1, если сессия началась утром и 0, если сессия началась позже (будем считать, что утро это если `start_hour равен` 11 или меньше).\n",
    "\n",
    "**Посчитйте ROC AUC на отложенной выборке для выборки с:**\n",
    "- сайтами, `start_month` и `start_hour`\n",
    "- сайтами, `start_month` и `morning`\n",
    "- сайтами, `start_month`, `start_hour` и `morning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hour(ts):\n",
    "    return ts.hour\n",
    "\n",
    "def get_morning(ts):\n",
    "    if ts.hour <= 11:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "new_train['start_hour'] = train_df['time1'].apply(get_hour)\n",
    "new_test['start_hour'] = test_df['time1'].apply(get_hour)\n",
    "new_train['morning'] = train_df['time1'].apply(get_morning)\n",
    "new_test['morning'] = test_df['time1'].apply(get_morning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour_scaler = StandardScaler()\n",
    "hour_scaler.fit(new_train['start_hour'].astype('float64').values.reshape(-1, 1))\n",
    "new_train['start_hour_s'] = hour_scaler.transform(new_train['start_hour'].astype('float64').values.reshape(-1, 1))\n",
    "new_test['start_hour_s'] = hour_scaler.transform(new_test['start_hour'].astype('float64').values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sess_length(row):\n",
    "    dropped_row = row.dropna()\n",
    "    length_ts = dropped_row.iloc[-1] - dropped_row.iloc[-(2%len(dropped_row))]\n",
    "    return length_ts/np.timedelta64(1, 's')\n",
    "\n",
    "new_train['sess_length'] = train_df[times].apply(get_sess_length, axis=1)\n",
    "new_test['sess_length'] = test_df[times].apply(get_sess_length, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale_feature(new_train, new_test, 'sess_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_site_count(row):\n",
    "    dropped_row = row.dropna()\n",
    "    return len(dropped_row)\n",
    "\n",
    "new_train['site_count'] = train_df[times].apply(get_site_count, axis=1)\n",
    "new_test['site_count'] = test_df[times].apply(get_site_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_feature(new_train, new_test, 'site_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_s</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_s</th>\n",
       "      <th>sess_length</th>\n",
       "      <th>sess_length_s</th>\n",
       "      <th>site_count</th>\n",
       "      <th>site_count_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201410</td>\n",
       "      <td>0.822948</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.407823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.203780</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201407</td>\n",
       "      <td>0.752287</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.407823</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.029935</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201412</td>\n",
       "      <td>0.870055</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858234</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.173295</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201411</td>\n",
       "      <td>0.846501</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.724338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.203780</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201405</td>\n",
       "      <td>0.705179</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858234</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.163134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_month  year_month_s  start_hour  morning  start_hour_s  \\\n",
       "session_id                                                                \n",
       "1               201410      0.822948          11        1     -0.407823   \n",
       "2               201407      0.752287          11        1     -0.407823   \n",
       "3               201412      0.870055          15        0      0.858234   \n",
       "4               201411      0.846501          10        1     -0.724338   \n",
       "5               201405      0.705179          15        0      0.858234   \n",
       "\n",
       "            sess_length  sess_length_s  site_count  site_count_s  \n",
       "session_id                                                        \n",
       "1                   0.0      -0.203780          10      0.278784  \n",
       "2                  23.0       0.029935          10      0.278784  \n",
       "3                   3.0      -0.173295          10      0.278784  \n",
       "4                   0.0      -0.203780          10      0.278784  \n",
       "5                   4.0      -0.163134          10      0.278784  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_2feat_start_hour = csr_matrix(hstack([X_train_sparse, \n",
    "#                                               new_train[['year_month_s', 'start_hour']].values]))\n",
    "\n",
    "# X_train_2feat_morning = csr_matrix(hstack([X_train_sparse, \n",
    "#                                               new_train[['year_month_s', 'morning']].values]))\n",
    "\n",
    "X_train_3feat = csr_matrix(hstack([X_train_sparse, \n",
    "                                   new_train[['year_month_s', 'start_hour_s', 'morning']].values]))\n",
    "\n",
    "X_train_4feat = csr_matrix(hstack([X_train_sparse, \n",
    "                                   new_train[['year_month_s', 'start_hour_s', 'morning', 'sess_length_s']].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(get_auc_lr_valid(X_train_2feat_morning, y_train))\n",
    "# print(get_auc_lr_valid(X_train_2feat_start_hour, y_train))\n",
    "# print(get_auc_lr_valid(X_train_3feat, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_3feat = csr_matrix(hstack([X_test_sparse, \n",
    "                                  new_test[['year_month_s', 'start_hour', 'morning']].values]))\n",
    "\n",
    "X_test_4feat = csr_matrix(hstack([X_test_sparse, \n",
    "                                  new_test[['year_month_s', 'start_hour', 'morning', 'sess_length_s']].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python35-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "est = LogisticRegression(random_state=17, n_jobs=-1, C=0.1)\n",
    "est.fit(X_train_3feat, y_train)\n",
    "y_pred = est.predict_proba(X_test_3feat)[:, 1]\n",
    "write_to_submission_file(y_pred, './../../data/alice_result2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Подбор коэффицициента регуляризации\n",
    "\n",
    "Итак, мы ввели признаки, которые улучшают качество нашей модели по сравнению с первым бейслайном. Можем ли мы добиться большего значения метрики? После того, как мы сформировали обучающую и тестовую выборки, почти всегда имеет смысл подобрать оптимальные гиперпараметры -- характеристики модели, которые не изменяются во время обучения. Например, на 3 неделе вы проходили решающие деревья, глубина дерева это гиперпараметр, а признак, по которому происходит ветвление и его значение -- нет. В используемой нами логистической регрессии веса каждого признака изменяются и во время обучения находится их оптимальные значения, а коэффициент регуляризации остается постоянным. Это тот гиперпараметр, который мы сейчас будем оптимизировать.\n",
    "\n",
    "Посчитайте качество на отложенной выборке с коэффициентом регуляризации, который по умолчанию `C=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95747123730027317"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_4feat, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постараемся побить этот результат за счет оптимизации коэффициента регуляризации. Возьмем набор возможных значений C и для каждого из них посчитаем значение метрики на отложенной выборке.\n",
    "\n",
    "Найдите `C` из `np.logspace(-3, 1, 10)`, при котором ROC AUC на отложенной выборке максимален. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.001 ROC_AUC:  0.823932622161\n",
      "C:  0.00278255940221 ROC_AUC:  0.8934026784\n",
      "C:  0.00774263682681 ROC_AUC:  0.939785739473\n",
      "C:  0.0215443469003 ROC_AUC:  0.956403466982\n",
      "C:  0.0599484250319 ROC_AUC:  0.960467892772\n",
      "C:  0.16681005372 ROC_AUC:  0.961099331698\n",
      "C:  0.464158883361 ROC_AUC:  0.960268634015\n",
      "C:  1.29154966501 ROC_AUC:  0.958622786869\n",
      "C:  3.5938136638 ROC_AUC:  0.955717231897\n",
      "C:  10.0 ROC_AUC:  0.951314820987\n"
     ]
    }
   ],
   "source": [
    "for C in np.logspace(-3, 1, 10):\n",
    "    print('C: ', C, 'ROC_AUC: ', get_auc_lr_valid(X_train_3feat, y_train, C=C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обучите модель с найденным оптимальным значением коэффициента регуляризации и с построенными признаками `start_hour`, `start_month` и `morning`. Если вы все сделали правильно и загрузите это решение, то повторите второй бенчмарк соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960269388783\n"
     ]
    }
   ],
   "source": [
    "est = LogisticRegression(random_state=17, C=0.464158883361)\n",
    "est.fit(X_train_3feat, y_train)\n",
    "y_pred = est.predict_proba(X_test_3feat)[:, 1]\n",
    "write_to_submission_file(y_pred, './../../data/alice_result3.csv')\n",
    "print(get_auc_lr_valid(X_train_3feat, y_train, C=0.464158883361))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "0.96215593145"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
