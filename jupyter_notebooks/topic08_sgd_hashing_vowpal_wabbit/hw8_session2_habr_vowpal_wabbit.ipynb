{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание № 8\n",
    "## <center> Vowpal Wabbit в задаче прогнозирования популярности статьи на хабре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании надо побить бенчмарк в [соревновании](https://www.kaggle.com/c/habr-num-bookmarks) на Kaggle Inclass. Как это делать – ограничений нет (кроме, конечно, ручной разметки), прочитать правила можно [тут](https://www.kaggle.com/c/habr-num-bookmarks/rules). Ниже описаны инструкции, как это сделать с Vowpal Wabbit.\n",
    "\n",
    "Дедлайн: 31 октября 23:59 UTC +3. Решение надо будет загрузить по [ссылке](https://www.dropbox.com/request/g5WOPrxwvcYwADZCuoY7). В этом соревновании нет задачи победить. Цель – побить бенчмарк и продвинуться в [соревновании](https://mlcourse.arktur.io) по прогнозу популярности статьи на Medium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на одну из строчек в JSON-файле: считаем ее с помощью библиотеки json. Эта строчка соответствует [7-ой статье](https://habrahabr.ru/post/7/) на Хабре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 ../../data/train.json > ../../data/train1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/train1.json') as inp_json:\n",
    "    first_json = json.load(inp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['post_id', 'url', 'domain', 'content', 'polling', 'link_tags', '_timestamp', 'tags', 'meta_tags', 'published', 'hubs', '_id', 'title', 'flow', 'author', 'flags'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим 16 полей, перечислим некоторые из них:\n",
    "- _id, url - URL статьи\n",
    "- published – время публикации статьи\n",
    "- domain – сайт (например, habrahahbr.ru или geektimes.ru)\n",
    "- title – название статьи\n",
    "- content – текст статьи\n",
    "- hubs - перечисление хабов, к которым относится статья\n",
    "- tags – теги статьи\n",
    "- author – автор статьи, его ник и ссылка на профиль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'https://habrahabr.ru/post/7/',\n",
       " '_timestamp': 1493192186.0903192,\n",
       " 'author': {'name': 'Павел Титов',\n",
       "  'nickname': '@ptitov',\n",
       "  'url': 'https://habrahabr.ru/users/ptitov'},\n",
       " 'content': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.<br>\\r\\n<br>\\r\\nВозможно, это происходит при смене IP-адреса, но я не уверен.',\n",
       " 'domain': 'habrahabr.ru',\n",
       " 'flags': [],\n",
       " 'flow': None,\n",
       " 'hubs': [{'id': 'hub/habr',\n",
       "   'title': 'Хабрахабр',\n",
       "   'url': 'https://habrahabr.ru/hub/habr/'}],\n",
       " 'link_tags': {'alternate': 'https://habrahabr.ru/rss/post/7/',\n",
       "  'apple-touch-icon-precomposed': '/images/favicons/apple-touch-icon-152x152.png',\n",
       "  'canonical': 'https://habrahabr.ru/post/7/',\n",
       "  'icon': '/images/favicons/favicon-16x16.png',\n",
       "  'image_src': 'https://habrahabr.ru/i/habralogo.jpg',\n",
       "  'stylesheet': 'https://habracdn.net/habr/styles/1493134745/_build/global_main.css'},\n",
       " 'meta_tags': {'al:android:app_name': 'Habrahabr',\n",
       "  'al:android:package': 'ru.habrahabr',\n",
       "  'al:android:url': 'habrahabr://post/7',\n",
       "  'al:windows_phone:app_id': '460a6bd6-8955-470f-935e-9ea1726a6060',\n",
       "  'al:windows_phone:app_name': 'Habrahabr',\n",
       "  'al:windows_phone:url': 'habrahabr://post/7',\n",
       "  'apple-mobile-web-app-title': 'Хабрахабр',\n",
       "  'application-name': 'Хабрахабр',\n",
       "  'description': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.\\r\\n\\r\\nВозможно, это происходит при смене IP-адреса, но я не уверен.',\n",
       "  'fb:app_id': '444736788986613',\n",
       "  'keywords': 'логин, login',\n",
       "  'msapplication-TileColor': '#FFFFFF',\n",
       "  'msapplication-TileImage': 'mstile-144x144.png',\n",
       "  'og:description': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.  Возможно, это происходит при...',\n",
       "  'og:image': 'https://habrahabr.ru/i/habralogo.jpg',\n",
       "  'og:title': 'Самопроизвольное разлогинивание',\n",
       "  'og:type': 'article',\n",
       "  'og:url': 'https://habrahabr.ru/post/7/',\n",
       "  'pocket-site-verification': 'ed24b2b9721edf0a282c5b4a3232c4',\n",
       "  'referrer': 'unsafe-url',\n",
       "  'robots': 'noindex',\n",
       "  'twitter:card': 'summary',\n",
       "  'twitter:site': '@habrahabr',\n",
       "  'viewport': 'width=1024',\n",
       "  'yandex-verification': '67d46b975fa41645'},\n",
       " 'polling': None,\n",
       " 'post_id': 7,\n",
       " 'published': {'$date': '2006-07-15T01:48:00.000Z'},\n",
       " 'tags': ['логин', 'login'],\n",
       " 'title': 'Самопроизвольное разлогинивание',\n",
       " 'url': 'https://habrahabr.ru/post/7/'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://habrahabr.ru/post/7/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1493192186.0903192"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://habrahabr.ru/post/7/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'habrahabr.ru'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006-07-15T01:48:00.000Z'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['published']['$date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Самопроизвольное разлогинивание'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.<br>\\r\\n<br>\\r\\nВозможно, это происходит при смене IP-адреса, но я не уверен.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_json['polling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['post_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['flags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'hub/habr',\n",
       "  'title': 'Хабрахабр',\n",
       "  'url': 'https://habrahabr.ru/hub/habr/'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['hubs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_json['flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['логин', 'login']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Павел Титов',\n",
       " 'nickname': '@ptitov',\n",
       " 'url': 'https://habrahabr.ru/users/ptitov'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternate': 'https://habrahabr.ru/rss/post/7/',\n",
       " 'apple-touch-icon-precomposed': '/images/favicons/apple-touch-icon-152x152.png',\n",
       " 'canonical': 'https://habrahabr.ru/post/7/',\n",
       " 'icon': '/images/favicons/favicon-16x16.png',\n",
       " 'image_src': 'https://habrahabr.ru/i/habralogo.jpg',\n",
       " 'stylesheet': 'https://habracdn.net/habr/styles/1493134745/_build/global_main.css'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['link_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'al:android:app_name': 'Habrahabr',\n",
       " 'al:android:package': 'ru.habrahabr',\n",
       " 'al:android:url': 'habrahabr://post/7',\n",
       " 'al:windows_phone:app_id': '460a6bd6-8955-470f-935e-9ea1726a6060',\n",
       " 'al:windows_phone:app_name': 'Habrahabr',\n",
       " 'al:windows_phone:url': 'habrahabr://post/7',\n",
       " 'apple-mobile-web-app-title': 'Хабрахабр',\n",
       " 'application-name': 'Хабрахабр',\n",
       " 'description': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.\\r\\n\\r\\nВозможно, это происходит при смене IP-адреса, но я не уверен.',\n",
       " 'fb:app_id': '444736788986613',\n",
       " 'keywords': 'логин, login',\n",
       " 'msapplication-TileColor': '#FFFFFF',\n",
       " 'msapplication-TileImage': 'mstile-144x144.png',\n",
       " 'og:description': 'У меня такое ощущение, что logout время от времени происходит самопроизвольно, несмотря на то, что чекбокс про логине включен.  Возможно, это происходит при...',\n",
       " 'og:image': 'https://habrahabr.ru/i/habralogo.jpg',\n",
       " 'og:title': 'Самопроизвольное разлогинивание',\n",
       " 'og:type': 'article',\n",
       " 'og:url': 'https://habrahabr.ru/post/7/',\n",
       " 'pocket-site-verification': 'ed24b2b9721edf0a282c5b4a3232c4',\n",
       " 'referrer': 'unsafe-url',\n",
       " 'robots': 'noindex',\n",
       " 'twitter:card': 'summary',\n",
       " 'twitter:site': '@habrahabr',\n",
       " 'viewport': 'width=1024',\n",
       " 'yandex-verification': '67d46b975fa41645'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_json['meta_tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим ответы на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv('../../data/train_target.csv',\n",
    "                          index_col='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://habrahabr.ru/post/7/</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/11/</th>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/112/</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/1127/</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://geektimes.ru/post/12664/</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    target\n",
       "url                                       \n",
       "https://habrahabr.ru/post/7/      0.693147\n",
       "https://geektimes.ru/post/11/     1.098612\n",
       "https://geektimes.ru/post/112/    0.000000\n",
       "https://geektimes.ru/post/1127/   0.000000\n",
       "https://geektimes.ru/post/12664/  0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируйте обучающую выборку для Vowpal Wabbit, выберите признаки title, tags, domain, flow, author, и hubs из JSON-файла.\n",
    "От самого текста для начала просто возьмем его длину: постройте признак content_len – длина текста в миллионах символов.\n",
    "Также постройте признаки: час и месяц публикации статьи. Еще, конечно же, возьмите ответы на обучающей выборке из `train_target`. Ниже пример того, как могут выглядеть первые две строки нового файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931470000000001 |title �������������������������������� ���������������������������� |tags ���������� login |domain habrahabr.ru |flow None |author @ptitov |hubs ������������������ |num content_len:0.000199 month:7 hour:1\r\n",
      "1.0986120000000001 |title Stand-along c������������������ ������������ ������������������ �� ������������ �������������������� ���������� |tags �������������������� ����������������-�������������������� �������������������� �������� �������������� ���������� |domain geektimes.ru |flow None |author @AlexBruce |hubs ������������ �������� |num content_len:0.000988 month:7 hour:14\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/habr_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931470000000001 |title Самопроизвольное разлогинивание |tags логин login |domain habrahabr.ru |flow None |author @ptitov |hubs Хабрахабр |num content_len:0.0 month:7 hour:1\r\n",
      "1.0986120000000001 |title Stand-along cообщества против сообществ в рамках социальных сетей |tags сообщества интернет-сообщество социальные сети нишевой бренд |domain geektimes.ru |flow None |author @AlexBruce |hubs Чёрная дыра |num content_len:0.0 month:7 hour:14\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/habr_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import re\n",
    "\n",
    "def format_vw_obj(obj, label=1):\n",
    "    tags = \" \".join(obj['tags']).replace(':', ' ')\n",
    "    hubs = \" \".join([hub['title'] for hub in obj['hubs']]).replace(':', ' ')\n",
    "    title = obj['title'].replace(':', ' ')\n",
    "    pub = parser.parse(obj['published']['$date'])\n",
    "    morning = 1 if pub.hour < 11 else 0\n",
    "    evening = 1 if pub.hour > 20 else 0\n",
    "    return \"{} |title {} |tags {} |domain {} |flow {} |author {} |hubs {} |num content_len:{} month:{} hour:{} ev:{} mor:{}\" \\\n",
    "            .format(label, title, tags, obj['domain'], obj['flow'], obj['author']['nickname'], hubs, round(len(obj['content'])/10**6, 2), pub.month, pub.hour, evening, morning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000 ../../data/train.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l '../../data/train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e8e4d32bd416ca4d2f9e68ae17a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/train.json', encoding=\"utf8\") as inp_json, \\\n",
    "     open('../../data/habr_train.vw', 'w', encoding=\"utf8\") as out_vw:\n",
    "    for line in tqdm_notebook(inp_json):\n",
    "        data_json = json.loads(line)\n",
    "        line = format_vw_obj(data_json, train_target.loc[data_json['url']].target)\n",
    "        out_vw.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!split -l 60000 '../../data/habr_train.vw' '../../data/habr_train_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../../data/habr_train_aa ../../data/my_train.vw\n",
    "!mv ../../data/habr_train_ab ../../data/my_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 ../../data/my_train.vw\n",
      "60000 ../../data/my_valid.vw\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../../data/my_train.vw\n",
    "!wc -l ../../data/my_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cut -f 1 -d ' ' ../../data/my_valid.vw > ../../data/my_valid_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделайте все то же с тестовой выборкой, вместо ответов подсовывая что угодно, например, единицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a8c34ab6a44ecb7b6a06839ab4365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/test.json', encoding=\"utf8\") as inp_json, \\\n",
    "     open('../../data/habr_test.vw', 'w', encoding=\"utf8\") as out_vw:\n",
    "    for line in tqdm_notebook(inp_json):\n",
    "        data_json = json.loads(line)\n",
    "        line = format_vw_obj(data_json)\n",
    "        out_vw.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../../data/habr_test.vw ../../data/my_test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор того, как валидировать модель, остается за Вами. Проще всего, конечно, сделать отложенную выборку. Бенчмарк, который Вы видите в соревновании (**vw_baseline.csv**) и который надо побить, получен с Vowpal Wabbit, 3 проходами по выборке (не забываем удалять кэш), биграммами и настроенными гиперпараметрами `bits`, `learning_rate` и `power_t`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import itertools\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np.loadtxt('../../data/my_valid_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vw_model(train_vw_file, model_filename, ngram=1, passes=1, seed=17, bit=18, learning_rate=0.5, power_t=0.5, quiet=False):\n",
    "    init_time = time()\n",
    "    vw_call_string = ('vw -d {} -f {} --loss_function quantile --random_seed {seed}') \\\n",
    "                     .format(train_vw_file, model_filename, seed=seed)\n",
    "    if ngram > 1:\n",
    "         vw_call_string += ' --ngram {}'.format(ngram)\n",
    "            \n",
    "    if passes > 1:\n",
    "         vw_call_string += ' -k --passes {} --cache_file {}'.format(passes, \n",
    "                            model_filename.replace('.vw', '.cache'))\n",
    "          \n",
    "    if bit > 0:\n",
    "        vw_call_string += ' -b {}'.format(bit)\n",
    "        \n",
    "    if learning_rate > 0:\n",
    "        vw_call_string += ' -l {}'.format(learning_rate)\n",
    "        \n",
    "    if power_t > 0:\n",
    "        vw_call_string += ' --power_t {}'.format(power_t)\n",
    "        \n",
    "    if quiet:\n",
    "        vw_call_string += ' --quiet'\n",
    "    \n",
    "    \n",
    "    print('\\n', vw_call_string) \n",
    "    res = os.system(vw_call_string)\n",
    "    print('Success. Elapsed: {} sec.'.format(round(time() - init_time, 3))\n",
    "          if not res else 'Failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vw_model(model_filename, test_vw_file, prediction_filename, true_labels, seed=17, quiet=False):\n",
    "    init_time = time()\n",
    "    vw_call_string = ('vw -t -i {} -d {} -p {} --random_seed {}') \\\n",
    "                     .format(model_filename, test_vw_file, prediction_filename, seed)\n",
    "    if quiet:\n",
    "        vw_call_string += ' --quiet'\n",
    "        \n",
    "#     print(vw_call_string) \n",
    "    res = os.system(vw_call_string)\n",
    "    \n",
    "    if not res: # the call resulted OK\n",
    "        vw_pred = np.loadtxt(prediction_filename)\n",
    "        print(\"MAE: {}. Elapsed: {} sec.\".format(\n",
    "            round(mean_absolute_error(true_labels, vw_pred), 2), \n",
    "            round(time() - init_time, 3)))\n",
    "    else:\n",
    "        print('Failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9 --power_t 0.7\n",
      "Success. Elapsed: 5.954 sec.\n",
      "MAE: 0.93. Elapsed: 0.894 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9 --power_t 0.76\n",
      "Success. Elapsed: 5.731 sec.\n",
      "MAE: 0.94. Elapsed: 0.83 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9 --power_t 0.82\n",
      "Success. Elapsed: 5.758 sec.\n",
      "MAE: 0.96. Elapsed: 0.714 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9 --power_t 0.88\n",
      "Success. Elapsed: 5.964 sec.\n",
      "MAE: 0.98. Elapsed: 0.719 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9 --power_t 0.94\n",
      "Success. Elapsed: 6.377 sec.\n",
      "MAE: 1.0. Elapsed: 0.682 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9 --power_t 1.0\n",
      "Success. Elapsed: 5.781 sec.\n",
      "MAE: 1.01. Elapsed: 0.67 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9400000000000001 --power_t 0.7\n",
      "Success. Elapsed: 5.652 sec.\n",
      "MAE: 0.93. Elapsed: 0.791 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9400000000000001 --power_t 0.76\n",
      "Success. Elapsed: 5.56 sec.\n",
      "MAE: 0.94. Elapsed: 0.74 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9400000000000001 --power_t 0.82\n",
      "Success. Elapsed: 5.606 sec.\n",
      "MAE: 0.96. Elapsed: 0.667 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9400000000000001 --power_t 0.88\n",
      "Success. Elapsed: 5.707 sec.\n",
      "MAE: 0.98. Elapsed: 0.717 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9400000000000001 --power_t 0.94\n",
      "Success. Elapsed: 6.534 sec.\n",
      "MAE: 1.0. Elapsed: 0.647 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9400000000000001 --power_t 1.0\n",
      "Success. Elapsed: 5.461 sec.\n",
      "MAE: 1.01. Elapsed: 0.67 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9800000000000001 --power_t 0.7\n",
      "Success. Elapsed: 5.615 sec.\n",
      "MAE: 0.93. Elapsed: 0.66 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9800000000000001 --power_t 0.76\n",
      "Success. Elapsed: 5.544 sec.\n",
      "MAE: 0.94. Elapsed: 0.712 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9800000000000001 --power_t 0.82\n",
      "Success. Elapsed: 5.667 sec.\n",
      "MAE: 0.96. Elapsed: 0.694 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9800000000000001 --power_t 0.88\n",
      "Success. Elapsed: 5.586 sec.\n",
      "MAE: 0.98. Elapsed: 0.667 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9800000000000001 --power_t 0.94\n",
      "Success. Elapsed: 6.48 sec.\n",
      "MAE: 1.0. Elapsed: 0.681 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 0.9800000000000001 --power_t 1.0\n",
      "Success. Elapsed: 7.224 sec.\n",
      "MAE: 1.01. Elapsed: 0.678 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.02 --power_t 0.7\n",
      "Success. Elapsed: 5.568 sec.\n",
      "MAE: 0.93. Elapsed: 0.732 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.02 --power_t 0.76\n",
      "Success. Elapsed: 5.754 sec.\n",
      "MAE: 0.94. Elapsed: 0.725 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.02 --power_t 0.82\n",
      "Success. Elapsed: 5.731 sec.\n",
      "MAE: 0.96. Elapsed: 0.756 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.02 --power_t 0.88\n",
      "Success. Elapsed: 5.676 sec.\n",
      "MAE: 0.98. Elapsed: 0.678 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.02 --power_t 0.94\n",
      "Success. Elapsed: 6.473 sec.\n",
      "MAE: 1.0. Elapsed: 0.696 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.02 --power_t 1.0\n",
      "Success. Elapsed: 5.364 sec.\n",
      "MAE: 1.01. Elapsed: 0.69 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.06 --power_t 0.7\n",
      "Success. Elapsed: 5.622 sec.\n",
      "MAE: 0.93. Elapsed: 0.669 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.06 --power_t 0.76\n",
      "Success. Elapsed: 5.462 sec.\n",
      "MAE: 0.94. Elapsed: 0.75 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.06 --power_t 0.82\n",
      "Success. Elapsed: 5.589 sec.\n",
      "MAE: 0.96. Elapsed: 0.654 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.06 --power_t 0.88\n",
      "Success. Elapsed: 5.496 sec.\n",
      "MAE: 0.98. Elapsed: 0.908 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.06 --power_t 0.94\n",
      "Success. Elapsed: 6.508 sec.\n",
      "MAE: 1.0. Elapsed: 0.905 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.06 --power_t 1.0\n",
      "Success. Elapsed: 5.347 sec.\n",
      "MAE: 1.01. Elapsed: 0.675 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.1 --power_t 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. Elapsed: 5.513 sec.\n",
      "MAE: 0.93. Elapsed: 0.676 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.1 --power_t 0.76\n",
      "Success. Elapsed: 5.61 sec.\n",
      "MAE: 0.94. Elapsed: 0.656 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.1 --power_t 0.82\n",
      "Success. Elapsed: 5.596 sec.\n",
      "MAE: 0.96. Elapsed: 0.655 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.1 --power_t 0.88\n",
      "Success. Elapsed: 5.643 sec.\n",
      "MAE: 0.98. Elapsed: 0.657 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.1 --power_t 0.94\n",
      "Success. Elapsed: 6.426 sec.\n",
      "MAE: 1.0. Elapsed: 0.672 sec.\n",
      "\n",
      " vw -d ../../data/my_train.vw -f ../../data/my_model_train.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1.1 --power_t 1.0\n",
      "Success. Elapsed: 5.952 sec.\n",
      "MAE: 1.01. Elapsed: 0.662 sec.\n"
     ]
    }
   ],
   "source": [
    "bits = [26]\n",
    "learning_rate = np.linspace(0.9, 1.1, 6)\n",
    "power_t = np.linspace(0.7, 1, 6)\n",
    "\n",
    "for i, (bit, lear_rate, power_t_arg) in enumerate(itertools.product(bits, learning_rate, power_t)):\n",
    "    train_vw_model('../../data/my_train.vw', '../../data/my_model_train.vw', \n",
    "                   ngram=2, passes=3, seed=17, quiet=False, bit=bit, learning_rate=lear_rate, power_t=power_t_arg)\n",
    "    test_vw_model(model_filename='../../data/my_model_train.vw', test_vw_file='../../data/my_valid.vw', \n",
    "              prediction_filename='../../data/my_pred_train.vw',\n",
    "              true_labels=y_valid, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = ../../data/my_model_test.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 1\n",
      "initial_t = 0\n",
      "power_t = 0.7\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = ../../data/my_model_train.cache\n",
      "Reading datafile = ../../data/my_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.346574 0.346574            1            1.0   0.6931   0.0000       17\n",
      "0.264460 0.182346            2            2.0   1.0986   0.7339       37\n",
      "0.200145 0.135831            4            4.0   0.0000   0.2231       45\n",
      "0.672408 1.144670            8            8.0   4.9698   0.3764       41\n",
      "0.822268 0.972128           16           16.0   2.3026   1.2408       33\n",
      "0.961349 1.100430           32           32.0   2.8904   3.6216       25\n",
      "0.847553 0.733756           64           64.0   0.0000   2.1487       21\n",
      "0.738753 0.629953          128          128.0   5.1475   1.5390       23\n",
      "0.657426 0.576099          256          256.0   4.7707   3.9440       41\n",
      "0.608992 0.560559          512          512.0   3.1355   1.7065       29\n",
      "0.566494 0.523995         1024         1024.0   6.4785   5.0727       37\n",
      "0.538667 0.510840         2048         2048.0   5.7236   5.4092       45\n",
      "0.499228 0.459788         4096         4096.0   3.3322   3.1737       29\n",
      "0.465660 0.432093         8192         8192.0   4.1589   2.2043       47\n",
      "0.436996 0.408333        16384        16384.0   2.7081   3.6170       23\n",
      "0.403363 0.369729        32768        32768.0   4.1744   2.8807       43\n",
      "0.370058 0.370058        65536        65536.0   3.0910   3.0045       41 h\n",
      "0.358650 0.347244       131072       131072.0   4.9200   4.8222       37 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 54000\n",
      "passes used = 3\n",
      "weighted example sum = 162000.000000\n",
      "weighted label sum = 568539.954016\n",
      "average loss = 0.345151 h\n",
      "total feature number = 6734790\n",
      "MAE: 0.93. Elapsed: 0.979 sec.\n"
     ]
    }
   ],
   "source": [
    "!vw -d ../../data/my_train.vw -f ../../data/my_model_test.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1 --power_t 0.7\n",
    "test_vw_model(model_filename='../../data/my_model_test.vw', test_vw_file='../../data/my_valid.vw', \n",
    "              prediction_filename='../../data/my_pred_test.vw',\n",
    "              true_labels=y_valid, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw -d ../../data/habr_train.vw -f ../../data/my_model.vw --loss_function quantile --random_seed 17 --ngram 2 -k --passes 3 --cache_file ../../data/my_model_train.cache -b 26 -l 1 --power_t 0.85 --quiet\n",
    "!vw -i ../../data/my_model.vw -t -d ../../data/my_test.vw -p ../../data/habr_pred.vw --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('../../data/sample_submission.csv', \n",
    "                         index_col='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/habr_pred.vw', encoding=\"utf8\") as f:\n",
    "    preds = np.array([float(val) for val in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_submission = sample_sub.copy()\n",
    "your_submission['target'] = preds\n",
    "your_submission.to_csv('../../data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для получения баллов в #mlcourse_open команда (из 1 человека) должна называться в точном соответствии с тем, как оно записано в рейтинге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
